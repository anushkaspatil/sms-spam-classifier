{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"train-data.tsv\",sep = \"\\t\",header=None)\n",
        "df.columns = ['label','message']\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('label').describe().T"
      ],
      "metadata": {
        "id": "0qRWQJKNffku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_msg = df[df.label =='ham']\n",
        "spam_msg = df[df.label=='spam']\n",
        "# Create numpy list to visualize using wordcloud\n",
        "\n",
        "ham_msg_text = \" \".join(ham_msg.message.to_numpy().tolist())\n",
        "spam_msg_text = \" \".join(spam_msg.message.to_numpy().tolist())\n",
        "print(ham_msg_text)\n",
        "print(spam_msg_text)"
      ],
      "metadata": {
        "id": "LCjJBalVgQTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "ham_msg_cloud = WordCloud(width =320, height =160, stopwords=STOPWORDS,max_font_size=50, background_color =\"black\", colormap='Blues').generate(ham_msg_text)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(ham_msg_cloud, interpolation='bilinear')\n",
        "plt.axis('off') # turn off axis\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ghVpaWaihjEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "ham_msg_cloud = WordCloud(width =320, height =160, stopwords=STOPWORDS,max_font_size=50, background_color =\"white\", colormap='autumn').generate(spam_msg_text)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(ham_msg_cloud, interpolation='bilinear')\n",
        "plt.axis('off') # turn off axis\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cp86LeoniINp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert 'label' to categorical type\n",
        "df['label'] = df['label'].astype('category')\n",
        "\n",
        "# Create count plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.show()\n",
        "\n",
        "# Percentage of spam messages\n",
        "spam_percentage = (len(df[df['label'] == 'spam']) / len(df)) * 100\n",
        "ham_percentage = (len(df[df['label'] == 'ham']) / len(df)) * 100\n",
        "\n",
        "print(f\"Percentage of spam messages: {spam_percentage:.2f}%\")\n",
        "print(f\"Percentage of ham messages: {ham_percentage:.2f}%\")\n"
      ],
      "metadata": {
        "id": "vm7tClNpnQzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_msg_df = ham_msg.sample(n = len(spam_msg), random_state = 0)\n",
        "spam_msg_df = spam_msg\n",
        "print(ham_msg_df.shape, spam_msg_df.shape)#(747, 2) (747, 2)\n"
      ],
      "metadata": {
        "id": "kj7VmDT_imhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg_df = ham_msg_df.append(spam_msg_df).reset_index(drop=True)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.countplot(x='label',data = df)\n",
        "plt.title('Distribution of ham and spam email messages (after downsampling)')"
      ],
      "metadata": {
        "id": "2Ib5ekSRpY8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get length column for each text\n",
        "msg_df['text_length'] = msg_df['message'].apply(len) #Calculate average length by label types\n",
        "labels = msg_df.groupby('label').mean()\n",
        "labels"
      ],
      "metadata": {
        "id": "v5vp42Yuqx9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"valid-data.tsv\",sep='\\t', header= None)\n",
        "df_test.columns =['label', 'message']\n",
        "df_test.tail()"
      ],
      "metadata": {
        "id": "CbUGXuWtr8sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msg_df['msg_type']= msg_df['label'].map({'ham': 0, 'spam': 1})\n",
        "df_test['msg_type']= df_test['label'].map({'ham': 0, 'spam': 1})\n",
        "print(msg_df.tail())\n",
        "print(df_test.tail())\n"
      ],
      "metadata": {
        "id": "RY9udXxbs1Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = msg_df['msg_type']\n",
        "train_msg = msg_df['message']\n",
        "test_msg = df_test['message']\n",
        "test_label = df_test['msg_type']\n",
        "print(test_msg)\n",
        "print(train_msg)"
      ],
      "metadata": {
        "id": "qgZqrsjZtDaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining pre-processing hyperparameters\n",
        "max_len = 50\n",
        "trunc_type = \"post\"\n",
        "padding_type = \"post\"\n",
        "oov_tok = \"\"\n",
        "vocab_size = 500"
      ],
      "metadata": {
        "id": "nQk9UNbhtRQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras"
      ],
      "metadata": {
        "id": "XQaLjdMHuKVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer(num_words = vocab_size, char_level=False, oov_token = oov_tok)\n",
        "tokenizer.fit_on_texts(train_msg)"
      ],
      "metadata": {
        "id": "Qe3Ft3M7uZwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "tot_words = len(word_index)\n",
        "print('There are %s unique tokens in training data. ' % tot_words)"
      ],
      "metadata": {
        "id": "tx9xfqtIwQjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_sequences = tokenizer.texts_to_sequences(train_msg)\n",
        "training_padded = pad_sequences (training_sequences, maxlen = max_len, padding = padding_type, truncating = trunc_type )\n",
        "testing_sequences = tokenizer.texts_to_sequences(test_msg)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen = max_len,padding = padding_type, truncating = trunc_type)"
      ],
      "metadata": {
        "id": "SQY15yRbwiGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training tensor: ', training_padded.shape)\n",
        "print('Shape of testing tensor: ', testing_padded.shape)"
      ],
      "metadata": {
        "id": "alBa9C-Iwtg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_padded[0])\n"
      ],
      "metadata": {
        "id": "lEjebio_wtXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 500 # As defined earlier\n",
        "embedding_dim = 16\n",
        "drop_value = 0.2 # dropout\n",
        "n_dense = 24"
      ],
      "metadata": {
        "id": "FIKuCHs_w_mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout, LSTM, Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dropout(drop_value))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "nj5ZCDBFxDZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "UsoocHTWqdP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer='adam' ,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nIvIAEsHqix2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
        "history = model.fit(training_padded, train_label, epochs=num_epochs, validation_data=(testing_padded, test_label),callbacks =[early_stop], verbose=2)"
      ],
      "metadata": {
        "id": "ejThZB_CqqOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(testing_padded, test_label)"
      ],
      "metadata": {
        "id": "AT2xA22irKaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pd.DataFrame(history.history)"
      ],
      "metadata": {
        "id": "Q-0FK7hPrPrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.rename(columns = {'loss': 'Training_Loss', 'accuracy': 'Training_Accuracy', 'val_loss': 'Validation_Loss', 'val_accuracy': 'Validation_Accuracy'}, inplace = True)"
      ],
      "metadata": {
        "id": "AaAdSMIdrUVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs1(var1, var2, string):\n",
        "    metrics[[var1, var2]].plot()\n",
        "    plt.title('Training and Validation ' + string)\n",
        "    plt.xlabel ('Number of epochs')\n",
        "    plt.ylabel(string)\n",
        "    plt.legend([var1, var2])"
      ],
      "metadata": {
        "id": "Y-F49lF_rZPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphs1('Training_Loss', 'Validation_Loss', 'loss')"
      ],
      "metadata": {
        "id": "WAq3yTFtrcOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_graphs1('Training_Accuracy', 'Validation_Accuracy', 'accuracy')"
      ],
      "metadata": {
        "id": "JNUnr06jreX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text1):\n",
        "\n",
        "  pred_text = []\n",
        "  pred_text.append(pred_text1)\n",
        "  new_seq = tokenizer.texts_to_sequences(pred_text)\n",
        "  padded = pad_sequences(new_seq, maxlen =max_len,padding = padding_type,truncating=trunc_type)\n",
        "  prediction = model.predict(padded)\n",
        "  for i in prediction:\n",
        "    if i > 0.5:\n",
        "      return((float(i),\"spam\"))\n",
        "    else:\n",
        "      return((float(i),\"ham\"))\n",
        "\n",
        "pred_text = \" you have won £1000 cash! call to claim\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxotov85SjsC"
      },
      "outputs": [],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-2avnjqrthO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}